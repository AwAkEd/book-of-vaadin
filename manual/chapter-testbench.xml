<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="testbench">
	<title>Vaadin TestBench</title>

    <para>
        This chapter describes the installation and use of the commercial Vaadin TestBench
        product.
    </para>

    <section xml:id="testbench.overview">
        <title>Overview</title>

        <para>
            Quality assurance is one of the cornerstones of modern software
            development. Extending throughout the entire development process, quality
            assurance is the thread that binds the end product to the requirements. In
            iterative development processes, with ever shorter release cycles and
            continuous integration, the role of regression testing is central. The special
            nature of web applications creates many unique requirements for regression
            testing.
        </para>

        <para>
            Vaadin TestBench makes it possible to automate the regression testing of web
            applications that use Vaadin. You develop test cases as JUnit tests along your
            application code. A recorder that runs in browser creates JUnit test stubs,
            which you can then refine. You can compile the JUnit tests and run them as
            many times as you want, on multiple browser and operating system
            platforms. The test results are collected for later analysis.
        </para>

		<figure xml:id="figure.testbench.workflow">
			<title>TestBench Workflow</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/tt-workflow-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="130" smallscale="90%" align="center" fileref="img/testbench/tt-workflow-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>The main features of Vaadin TestBench are:</para>

        <itemizedlist>
            <listitem>
                <para>Record test case stubs in browser</para>
            </listitem>
            <listitem>
                <para>Develop JUnit tests in Java with the WebDriver</para>
            </listitem>
            <listitem>
                <para>Validate UI state by assertions and screen capture comparison</para>
            </listitem>
            <listitem>
                <para>Screen capture comparison with difference highlighting</para>
            </listitem>
            <listitem>
                <para>Distributed test grid for running tests</para>
            </listitem>
            <listitem>
                <para>Integration with unit testing</para>
            </listitem>
        </itemizedlist>

        <para>
            Execution of tests can be distributed over a grid of test nodes, which speeds
            up testing. The grid nodes can run different operating systems and have
            different browsers installed. In a minimal setup, such as for developing the
            tests, you can use Vaadin TestBench on just a single computer.
        </para>

        <para>
            Vaadin TestBench is based on the Selenium testing framework. Selenium is
            augmented with Vaadin-specific extensions, such as the screen capture feature.
        </para>

        <simplesect>
            <title>Licensing and Trial Period</title>

            <para>
                Vaadin TestBench is a commercial product sold under the Commercial Vaadin
                Add-On License (CVAL). You can purchase and download TestBench from the
                Vaadin Directory.
            </para>

            <para>
                You may try out the product for a free 30-day trial period, after which
                you are required to acquire the needed licenses.
            </para>
        </simplesect>
    </section>

    <section xml:id="testbench.components">
        <title>TestBench Components</title>

        <para>
            The main components of Vaadin TestBench are:
        </para>

        <itemizedlist>
            <listitem>
                <para>Vaadin TestBench Recorder</para>
            </listitem>
            <listitem>
                <para>Vaadin TestBench Library</para>
            </listitem>
        </itemizedlist>

        <para>
            The library includes WebDriver, which allows running tests as JUnit tests in a
            browser. It also includes the Grid Hub server, which you can use to run tests
            in a grid configuration.
        </para>

        <para>
            The components and a basic setup are illustrated in <xref
            linkend="figure.testbench.architecture"/>.
        </para>

		<figure xml:id="figure.testbench.architecture">
			<title>Vaadin TestBench Architecture</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/tt-architecture-simple-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="80" smallscale="100%" align="center" fileref="img/testbench/tt-architecture-simple-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>
            Recording test cases requires Vaadin TestBench Recorder, which is a Firefox
            extension that you install in your browser. It provides a control panel to
            record test cases and play them back. You can play the test cases right in the
            recorder. You can then export the tests as JUnit tests, which you can edit
            further and then execute with the WebDriver.
        </para>

        <para>
            The test suite and results from test runs are stored on the test server. A
            test suite includes JUnit tests and possible reference images for similarity
            tests.
        </para>

        <para>
            Vaadin TestBench Library provides the central control logic for:
        </para>

        <itemizedlist>
            <listitem>
                <para>
                    Executing tests with the WebDriver
                </para>
            </listitem>
            <listitem>
                <para>
                    Comparing screen captures with reference images
                </para>
            </listitem>
            <listitem>
                <para>
                    Controlling the execution of tests on the Vaadin TestBench Grid Hub
                </para>
            </listitem>
        </itemizedlist>

        <para>
            A basic Vaadin TestBench environment consists of:
        </para>

        <itemizedlist>
            <listitem>
                <para>
                    A workstation with Firefox and the TestBench Recorder for recording tests
                </para>
            </listitem>
            <listitem>
                <para>
                    A build/test server used to build, launch, and test the web application
                </para>
            </listitem>
            <listitem>
                <para>
                    A server running the Grid Hub
                </para>
            </listitem>
            <listitem>
                <para>
                    One or more servers running the tests
                </para>
            </listitem>
        </itemizedlist>

        <para>
            The workstation and servers can be separate computers or one computer can work in multiple roles.
        </para>
    </section>

    <section xml:id="testbench.requirements">
        <title>Requirements</title>

        <simplesect>
            <title>Requirements for Vaadin TestBench Recorder</title>

            <para>
                For recording and playback with Vaadin TestBench Recorder:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Mozilla Firefox 3.x or newer</para>
                </listitem>
            </itemizedlist>
        </simplesect>

        <simplesect>
            <title>Requirements for Automated Testing</title>

            <para>
                For running tests:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Java JDK 1.5 or newer</para>
                </listitem>
                <listitem>
                    <para>Browsers installed on test nodes</para>
                </listitem>
                <listitem>
                    <para>Apache Ant or some other way to run Ant scripts (recommended)</para>
                </listitem>
            </itemizedlist>
        </simplesect>

        <simplesect>
            <title>Continuous Integration Compatibility</title>

            <para>
                Vaadin TestBench works with continuous integration systems that support
                JUnit testing. It is tested to work on the TeamCity build management and
                continuous integration server.
            </para>
        </simplesect>

        <simplesect>
            <title>Known Compatibility Problems</title>

            <variablelist>
                <varlistentry>
                    <term><para>Firebug should be disabled</para></term>
                    <listitem>
                        <para>
                            In some cases, Firebug injects a <literal>&lt;div
                            id="_firebugConsole"&gt;</literal> element under the
                            <literal>&lt;body&gt;</literal> element (the element is
                            invisible in the Firebug's HTML structure browser). This can
                            disturb recording of test cases, especially when closing
                            notifications. Firebug 1.6 should fix this issue, but we still
                            encourage TestBench users to disable Firebug when recording or
                            playing test cases.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><para>Screenshots when running Internet Explorer 9 in Compatibility Mode</para></term>
                    <listitem>
                        <para>
                            Internet Explorer prior to version 9 adds a two-pixel border
                            around the content area. Version 9 no longer does this and as
                            a result screenshots taken using Internet Explorer 9 running
                            in compatibility mode (IE7/IE8) will include the two pixel
                            border, contrary to what the older versions of Internet
                            Explorer do.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </simplesect>
    </section>

    <section xml:id="testbench.installation">
        <title>Installing Vaadin TestBench</title>

        <para>
            Installation of Vaadin TestBench covers the following tasks:
        </para>

        <itemizedlist>
            <listitem>
                <para>Download and unpack the Vaadin TestBench installation package</para>
            </listitem>
            <listitem>
                <para>Install Vaadin TestBench Recorder</para>
            </listitem>
            <listitem>
                <para>Install Vaadin TestBench Library</para>
            </listitem>
        </itemizedlist>

        <para>
            At first, you only need to install the Recorder. It allows you to record and
            play back tests in the browser.
        </para>

        <para>
            Two basic installation types are covered in these instructions:
        </para>

        <itemizedlist>
            <listitem>
                <para>Test development installation on a workstation</para>
            </listitem>
            <listitem>
                <para>Distributed grid installation</para>
            </listitem>
        </itemizedlist>

        <section xml:id="testbench.installation.development">
            <title>Test Development Installation</title>

            <para>
                In a typical small test development setup, you install all the tools on a
                workstation; TestBench Recorder in your browser to record stubs, develop
                JUnit tests under an IDE such as Eclipse, and develop the launch scripts
                that are used for the distributed tests.  <!-- TODO See <xref
                linkend="testbench.installation.workstation-playback"/> for a quick test
                development setup. -->
            </para>
        </section>

        <section xml:id="testbench.installation.distributed">
            <title>A Distributed Test Environment</title>

            <para>
                A Vaadin TestBench grid consists of two categories of hosts:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Vaadin TestBench Grid Hub</para>
                </listitem>
                <listitem>
                    <para>Grid nodes running Vaadin TestBench</para>
                </listitem>
            </itemizedlist>

            <para>
                The hub is a service that handles communication between the JUnit test
                runner and the nodes. The nodes are services that perform the actual
                execution of test commands in the browser.
            </para>

            <para>
                The hub requires very little resources, so you would typically run it either in
                the test server or on one of the nodes.
            </para>

            <para>
                In a fully distributed setup, you install the Vaadin TestBench components on
                separate hosts. <!-- TODO -->
            </para>
        </section>

        <section xml:id="testbench.installation.downloading">
            <title>Downloading and Unpacking the Installation Package</title>

            <para>
                First, download the installation package
                <filename>vaadin-testbench-&version.testbench;.zip</filename> and extract
                the installation package where you can find it.
            </para>

            <simplesect>
                <title>Windows</title>

                <para>
                    In Windows, use the default ZIP decompression feature to extract the
                    package into your chosen directory, for example,
                    <filename>C:\dev</filename>.
                </para>

                <warning>
                    <title>Windows Zip Decompression Problem</title>

                    <para>
                        The default decompression program in Windows XP and Vista as well
                        as some versions of WinRAR cannot unpack the installation package
                        properly in certain cases. Decompression can result in an error
                        such as: "The system cannot find the file specified." This can
                        happen because the default decompression program is unable to
                        handle long file paths where the total length exceeds 256
                        characters. This can occur, for example, if you try to unpack the
                        package under Desktop. You should unpack the package directly into
                        <filename>C:\dev</filename> or some other short path or use
                        another decompression program.
                    </para>
                </warning>
            </simplesect>

            <simplesect>
                <title>Linux, MacOS X, and other UNIX</title>

                <para>
                    In Linux, Mac OS X, and other UNIX-like systems, use Info-ZIP or other ZIP
                    software with the command:
                </para>

                <screen><prompt>$</prompt> <command>unzip</command> <parameter>vaadin-testbench-&version.testbench;.zip</parameter></screen>

                <para>
                    The contents of the installation package will be extracted under the
                    <filename>vaadin-testbench</filename> installation directory in the
                    chosen directory.
                </para>
            </simplesect>
        </section>

        <section xml:id="testbench.installation.contents">
            <title>Installation Package Contents</title>

            <para>
                The installation package contains the following:
            </para>

            <variablelist>
                <varlistentry>
                    <term><filename>documentation</filename></term>
                    <listitem>
                        <para>
                            The documentation folder contains the TestBench library API documentation,
                            a PDF excerpt of this chapter of Book of Vaadin, and the
                            license.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>example</filename></term>
                    <listitem>
                        <para>
                            The example folder provides TestBench examples for both Ant
                            and Maven, including the build script and the JUnit test
                            source files.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>maven</filename></term>
                    <listitem>
                        <para>
                            The Maven folder contains version of the Vaadin TestBench
                            libraries that you can install in your local Maven
                            repository. Please follow the instructions in the
                            <filename>INSTALL</filename> text file.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-recorder</filename></term>
                    <listitem>
                        <para>
                            This folder constains the Vaadin TestBench Recorder, which you
                            can install in Firefox. Please follow the instructions in
                            <xref linkend="testbench.installation.recorder"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-standalone-x.x.x.jar</filename></term>
                    <listitem>
                        <para>
                            This is the Vaadin TestBench library. It is a standalone
                            library that includes the Selenium WebDriver and many other
                            required libraries.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-standalone-x.x.x-javadoc.jar</filename></term>
                    <listitem>
                        <para>
                            This is the JavaDoc API documentation for the TestBench
                            library. If you use Eclipse, you can associate the JAR with
                            the TestBench JAR in the project preferences, in the build
                            path library settings.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </section>

        <section xml:id="testbench.installation.recorder">
            <title>Installing the Recorder</title>

            <para>
                You need the Vaadin TestBench Recorder in a test development environment
                to record test cases and to export them as JUnit tests.
            </para>

            <para>
                After extracting the files from the installation package, do the following:
            </para>

            <orderedlist>
                <listitem>
                    <para>Change to the <filename>vaadin-testbench-recorder</filename> directory under the installation directory.</para>
                </listitem>
                <listitem>
                    <para>Open Mozilla Firefox</para>
                </listitem>
                <listitem>
                    <para>
                        Either drag and drop the
                        <filename>vaadin-testbench-recorder-&version.testbench;.xpi</filename> to an
                        open Firefox window or open it from the <guimenu>File</guimenu>
                        menu.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Firefox will ask if you want to install the TestBench Recorder extension. Click
                        <guibutton>Install Now</guibutton>.
                    </para>

                    <figure xml:id="figure.testbench.installation.recorder">
                        <title>Installing Vaadin TestBench Recorder</title>
                        <mediaobject>
                            <imageobject role="html">
                                <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-install.png"/>
                            </imageobject>
                            <imageobject role="fo">
                                <imagedata scale="90" smallscale="100%" align="center" fileref="img/testbench/screenshots/tt-recorder-install.png"/>
                            </imageobject>
                        </mediaobject>
                    </figure>
                </listitem>
                <listitem>
                    <para>
                        After the installation of the add-on is finished, Firefox offers
                        to restart. Click <guibutton>Restart Now</guibutton>.
                    </para>
                </listitem>
            </orderedlist>

            <para>
                Installation of a new version of Vaadin TestBench Recorder will
                overwrite an existing previous version.
            </para>

            <para>
                After Firefox has restarted, navigate to a Vaadin application for which
                you want to record test cases, such as <ulink
                url="http://demo.vaadin.com/sampler">http://demo.vaadin.com/sampler</ulink>.
            </para>
        </section>

        <section xml:id="testbench.rc-installation.os-settings">
            <title>Operating system settings</title>

            <para>
                Make any operating system settings that might interfere with the browser and how
                it is opened or closed. Typical problems include crash handler dialogs.
            </para>

            <para>
                On Windows, disable error reporting in case a browser crashes as follows:
            </para>

            <orderedlist>
                <listitem>
                    <para>
                        Open <menuchoice><guimenu>control panel</guimenu><guimenuitem>System</guimenuitem></menuchoice>
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Select <guilabel>Advanced</guilabel> tab
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Select <guilabel>Error reporting</guilabel>
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Check that <guilabel>Disable error reporting</guilabel> is selected
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Check that <guilabel>But notify me when critical errors occur</guilabel> is not selected
                    </para>
                </listitem>
            </orderedlist>
        </section>

        <section xml:id="testbench.rc-installation.screenshot-settings">
            <title>Settings for Screenshots</title>

            <para>
                The screenshot comparison feature requires that the user interface of
                the browser stays constant. The exact features that interfere with
                testing depend on the browser and the operating system.
            </para>

            <para>
                In general:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Disable the auto-hide function for the toolbar
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Check that the toolbar is either locked or unlocked on all test hosts
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Disable blinking cursor
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Use the same screen resolution on all test machines and check
                        that the maximized window is always the same size
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Configure browsers in the same manner on all machines (same toolbars visible, same
                        themes, etc)
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Use identical operating system themeing on every host
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Turn off any software that may suddenly pop up a new window
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Turn off screen saver
                    </para>
                </listitem>
            </itemizedlist>

            <para>
                If using Windows and Internet Explorer, you should give also the
                following setting:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Turn on <guilabel>Allow active content to run in files on My
                            Computer</guilabel> under <guilabel>Security
                            settings</guilabel>
                    </para>
                </listitem>
            </itemizedlist>
        </section>
    </section>

    <section xml:id="testbench.preparing">
        <title>Preparing an Application for Testing</title>

        <para>
            Vaadin TestBench can usually test Vaadin application as they are, especially
            if just taking screenshots. However, assertion on HTML elements require a DOM
            path to the element and this path is vulnerable to even small changes in the
            DOM structure. They might change because of your UI logic, or if a new Vaadin
            version has some small changes. To make such problems less common, you can use
            <emphasis>debug IDs</emphasis> to refer to components.
        </para>

        <programlisting><?pocket-size 65% ?><![CDATA[public class ApplicationToBeTested extends Application {
    public void init() { 
        final Window main = new Window("Test window");
        setMainWindow(main);
        
        // Create a button
        Button button = new Button("Push Me!");
        
        // Optional: give the button a unique debug ID
        button.setDebugId("main.button");
        
        // Do something when the button is clicked
        button.addListener(new ClickListener() {
            @Override
            public void buttonClick(ClickEvent event) {
                // This label will not have a set debug ID
                main.addComponent(new Label("Thanks!"));
            }
        });
        main.addComponent(button);
    }
}]]></programlisting>

        <para>
            The application is shown in <xref
            linkend="figure.testbench.preparing.application-to-be-tested"/>, with the
            button already clicked.
        </para>

        <figure xml:id="figure.testbench.preparing.application-to-be-tested">
            <title>A Simple Application To Be Tested</title>
            <mediaobject>
                <imageobject role="html">
                    <imagedata align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
                <imageobject role="fo">
                    <imagedata scale="120" smallscale="100%" align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
            </mediaobject>
        </figure>

        <para>
            The button caption would be accessible in a JUnit test with the following
            XPath expression: <literal>//div[@id='main.button']/span/span</literal>. For
            the label, the path would be from the page root. A recorded test case stub for
            the above application is given in <xref
            linkend="testbench.development.stub"/>, which is further refined in this
            chapter.
        </para>
    </section>

    <section xml:id="testbench.recorder">
        <title>Using Vaadin TestBench Recorder</title>

        <para>
            The Vaadin TestBench Recorder is used for recording and exporting JUnit test
            stubs that you can then develop further. The most important role for using the
            Recorder is to identify all user interface elements that you want to test -
            you can do all other test logic by coding. The elements are identified by
            their HTML document tree path. The path can be an absolute path from the page
            root, or use a debug ID that you can set in the application code.
        </para>

        <para>
            You can play back recoded test cases and use the Recorder to make assertions
            and take screenshots for screen capture comparison. Then, you export the test
            stubs as JUnit Java source files which you can then develop further.
        </para>
        
		<figure xml:id="figure.testbench.recorder.workflow">
			<title>Recorder Workflow</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/tt-recorder-workflow-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="120" smallscale="90%" align="center" fileref="img/testbench/tt-recorder-workflow-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>
            The Recorder is available only for Mozilla Firefox. To run the recorded tests
            in other browsers, you need to export them as JUnit tests and launch the other
            browsers with the WebDriver, as described later.
        </para>

        <section xml:id="testbench.recorder.starting">
            <title>Starting the Recorder</title>

            <para>
                To start the Recorder:
            </para>

            <orderedlist>
                <listitem>
                    <para>Open Mozilla Firefox</para>
                </listitem>
                <listitem>
                    <para>Open the page with the application that you want to test</para>
                </listitem>
                <listitem>
                    <para>Select <menuchoice><guimenu>Tools</guimenu><guimenuitem>Vaadin
                    TestBench Recorder</guimenuitem></menuchoice> in the Firefox
                    menu</para>
        
                    <figure xml:id="figure.testbench.recorder.open">
                    <title>Starting Vaadin TestBench Recorder</title>
                        <mediaobject>
                            <imageobject role="html">
                                <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-open.png"/>
                            </imageobject>
                            <imageobject role="fo">
                                <imagedata scale="80" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-recorder-open.png"/>
                            </imageobject>
                        </mediaobject>
                    </figure>
                </listitem>
            </orderedlist>
            
            <para>
                The Vaadin TestBench Recorder window will open, as shown in <xref
                linkend="figure.testbench.recorder.recording-1"/>.
            </para>

            <figure xml:id="figure.testbench.recorder.recording-1">
                <title>Vaadin TestBench Recorder Running</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/recorder-recording-1.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="100%" align="center" fileref="img/testbench/screenshots/recorder-recording-1.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Recording is automatically enabled when the Recorder starts. This is
                indicated by the pressed <inlinegraphic
                fileref="img/testbench/inline/inline-record-button.png"/>
                <guibutton>Record</guibutton> button.
            </para>
        </section>

        <section xml:id="testbench.recorder.recording">
            <title>Recording</title>

            <para>
                While recording, you can interact with the application in (almost) any way
                you like. The Recorder records the interaction as commands in a test
                script, which is shown in tabular format in the Table tab and as HTML
                source code in the Source tab.
            </para>

            <figure xml:id="figure.testbench.recorder.recording">
                <title>User Interaction Recorded as Commands</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-recording.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="100%" align="center" fileref="img/testbench/screenshots/tt-recorder-recording.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Please note the following:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Changing browser tabs or opening a new browser window is not
                        recommended, as any clicks and other actions will be recorded
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Passwords are considered to be normal text input and are stored in
                        plain text
                    </para>
                </listitem>
            </itemizedlist>

            <para>
                While recording, you can insert various commands such as assertions or
                take a screenshot by selecting the command from the Command list.
            </para>

            <para>
                When you are finished, click the <inlinegraphic
                fileref="img/testbench/inline/inline-record-button.png"/>
                <guibutton>Record</guibutton> button to stop recording.
            </para>
        </section>

        <section xml:id="testbench.recorder.playback">
            <title>Playing Back Tests</title>

            <para>
                After you have stopped recording, reset the application to the initial
                state and press <inlinegraphic
                fileref="img/testbench/inline/inline-play-button.png"/> <guibutton>Play
                current test</guibutton> to run the test again. You can use the
                <literal>&amp;restartApplication</literal> parameter for an application in
                the URL to restart it.
            </para>

            <para>
                You can also play back saved tests by opening a target test in the
                Recorder with
                <menuchoice><guimenu>File</guimenu><guimenuitem>Open</guimenuitem></menuchoice>.
            </para>

            <para>
                You can use the <inlinegraphic
                fileref="img/testbench/inline/inline-slider-fastslow.png"/> slider to
                control the playback speed, click <guibutton>Pause</guibutton> to
                interrupt the execution and <guibutton>Resume</guibutton> to
                continue. While paused, you can click <guibutton>Step</guibutton> to
                execute the script step-by-step.
            </para>

            <para>
                Check that the test works as intended and no unintended or invalid commands are
                found; a test should run without errors.
            </para>
        </section>

        <section xml:id="testbench.recorder.editing">
            <title>Editing Tests</title>

            <para>
                While the primary purpose of using the Recorder is to identify all user
                interface elements to be tested, you can also edit the tests at this
                point. You can insert various commands, such as assertions or taking a
                screenshot, in the test script during or after recording.
            </para>

            <para>
                You insert a command by selecting an insertion point in the test script
                and right-clicking an element in the browser. A context menu opens and
                shows a selection of Recorder commands at the bottom. Selecting
                <guimenuitem>Show All Available Commands</guimenuitem> shows more
                commands. Commands inserted from the sub-menu are automatically added to
                the top-level context menu.
            </para>

            <para>
                <xref linkend="figure.testbench.recorder.inserting"/> shows adding an
                assertion after calculating "6*7=" with the Calc demo.
            </para>

            <figure xml:id="figure.testbench.recorder.inserting">
                <title>Inserting commands in a test script</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/screenshots/tt-recorder-inserting.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="120" smallscale="75%" align="center" fileref="img/testbench/screenshots/tt-recorder-inserting.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                Inserting a command from the context menu automatically selects the
                command in the <guilabel>Command</guilabel> field and fills in the target
                and value parameters.
            </para>

            <para>
                You can also select the command manually from the
                <guilabel>Command</guilabel> list. The new command or comment will be
                added at the selected location, moving the selected location down. If the
                command requires a target element, click <guilabel>Select</guilabel> and
                then click an element in your application. A reference to the element is
                shown in the <guilabel>Target</guilabel> field and you can highlight the
                element by clicking <guilabel>Find</guilabel>. If the command expects some
                value, such as for comparing the element value, give it in the
                <guilabel>Value</guilabel> field.
            </para>

            <para>
                Commands in a test script can be changed by selecting a command and
                changing the command, target, or value.
            </para>
        </section>

        <section xml:id="testbench.recorder.exporting">
            <title>Exporting Tests</title>

            <para>
                Once you have are satisfied with a test case, you need to export it as a
                JUnit test case stub.
            </para>

            <para>
                You can save a test by selecting
                <menuchoice><guimenu>File</guimenu><guisubmenu>Export</guisubmenu><guimenuitem>JUnit
                Test</guimenuitem></menuchoice>.
            </para>

            <figure xml:id="figure.testbench.recorder.exporting">
                <title>Exporting Test Case as JUnit Test</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/recorder-export-testcase-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="80" smallscale="80%" align="center" fileref="img/testbench/recorder-export-testcase-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                In the dialog that opens, enter a file name for the Java source file. The
                file contains a Java class with name <classname>Testcase</classname>, so
                you might want to name the file as <filename>Testcase.java</filename>. You
                can rename the class later.
            </para>
        </section>

        <section xml:id="testbench.recorder.saving">
            <title>Saving Tests</title>

            <para>
                While exporting tests as JUnit tests is the normal case, the Recorder also
                allows saving test cases and test suites in a HTML format that can be
                loaded back in the Recorder. Vaadin TestBench does not support other use
                for these saved tests, but you may still find the feature useful if you
                like to develop test cases more with the Recorder.
            </para>
        </section>
    </section>

    <section xml:id="testbench.development">
        <title>Developing Tests</title>

        <para>
            Tests are developed using the Selenium WebDriver, which is augmented with
            Vaadin TestBench API features useful for testing Vaadin applications.
        </para>

        <para>
            Perhaps the easiest way to start developing tests is to use the Recorder
            to create a JUnit test stub, which is described in the next section.  The
            main purpose of the recorder is to help identify the HTML DOM paths of the
            user interface elements that you want to interact with and use for
            assertions. Once you get the hang of coding tests, you should be able to
            do it without using the Recorder. Working with debug IDs and using a web
            debugger, such as Firebug, is usually the easiest way to find out the DOM
            paths. You can also use the Recorder just to find the paths, and copy and
            paste them directly to your source code without going through the export
            hassle.
        </para>

        <section xml:id="testbench.development.stub">
            <title>Starting From a Stub</title>

            <para>
                Let us assume that you recorded a simple application, as described
                earlier, and exported it as a JUnit stub. You can add it to a project in a
                suitable package. You may want to keep your test classes in a separate
                source tree in your application project, or in an altogether separate
                project, so that you do not have to include them in the web application
                WAR. Having them in the same project may be nicer for version control
                purposes.
            </para>

            <para>
                You need to perform at least the following routine tasks:
            </para>

            <itemizedlist>
                <listitem>Rename the package</listitem>
                <listitem>Rename the class</listitem>
                <listitem>Check the base URL</listitem>
                <listitem>Clean up unnecessary code</listitem>
            </itemizedlist>

            <para>
                A JUnit stub will look somewhat as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[package com.example.tests;

import java.util.regex.Pattern;
import java.util.concurrent.TimeUnit;
import org.junit.*;
import static org.junit.Assert.*;
import static org.hamcrest.CoreMatchers.*;
import org.openqa.selenium.*;
import org.openqa.selenium.firefox.FirefoxDriver;
import org.openqa.selenium.support.ui.Select;
import com.vaadin.testbench.TestBench;
import com.vaadin.testbench.TestBenchTestCase;

public class Testcase1 extends TestBenchTestCase {
	private WebDriver driver;
	private String baseUrl;
	private StringBuffer verificationErrors = new StringBuffer();]]></programlisting>

            <para>
                The <parameter>verificationErrors</parameter> is used to collect some
                errors in some recorded commands, but can be removed if such commands are
                not used.
            </para>

            <simplesect xml:id="testbench.development.stub.setup">
                <title>Test Setup</title>

                <para>
                    The set-up method, annotated with <literal>@Before</literal>, makes
                    the basic configuration for the test. Most importantly, it creates the
                    <classname>WebDriver</classname> instance, which is for Firefox by
                    default. Drivers for different browsers extend the
                    <classname>RemoteWebDriver</classname> class - see the API type
                    hierarchy for the complete list.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[	@Before
	public void setUp() throws Exception {
		driver = TestBench.createDriver(new FirefoxDriver());
		baseUrl = "http://localhost:8080/myapp";
	}
]]]></programlisting>

                <para>
                    Check that the <parameter>baseUrl</parameter> is the correct URL for
                    the application. It might not be.
                </para>
            </simplesect>

            <simplesect xml:id="testbench.development.stub.testcase">
                <title>Test Case Stub</title>
                
                <para>
                    The test case methods are marked with <literal>@Test</literal>
                    annotation. They normally start by calling the
                    <methodname>get()</methodname> method in the driver. This loads the
                    URL in the browser.
                </para>

                <para>
                    Actual test commands usually call the
                    <methodname>findElement()</methodname> method in the driver to get
                    hold of an HTML element to work with. The button has the
                    <literal>main.button</literal> ID, as we set that ID for the
                    <classname>Button</classname> object with the
                    <methodname>setDebugId()</methodname> method in the application. The
                    HTML element is represented as a <classname>WebElement</classname>
                    object.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[	@Test
	public void testCase1() throws Exception {
		driver.get(baseUrl + "/myapp");
		assertEquals("Push Me!", driver.findElement(By.xpath(
            "//div[@id='main.button']/span/span")).getText());
		driver.findElement(By.xpath(
            "//div[@id='main.button']/span/span")).click();
		assertEquals("Thanks!", driver.findElement(By.xpath(
            "//div[@id='bookexamplestobetested-949693921']"
            "/div/div[2]/div/div[2]/div/div")).getText());
	}]]></programlisting>

                <para>
                    The <methodname>get()</methodname> call appends the app path to the
                    base URL. If it is already included in the base URL, you can remove
                    it.
                </para>
            </simplesect>

            <simplesect xml:id="testbench.development.stub.other">
                <title>After Testing</title>

                <para>
                    Finally after running all the test cases, the method annotated with
                    <literal>@After</literal> is called. You should always call
                    <methodname>quit()</methodname> for the driver.
                </para>

                <para>
                    The stub includes code for collecting verification errors. If you do
                    not collect those, as is often the case, you can remove the code.
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[    @After
    public void tearDown() throws Exception {
        driver.quit();

        String verificationErrorString =
            verificationErrors.toString();
        if (!"".equals(verificationErrorString)) {
            fail(verificationErrorString);
        }
    }]]></programlisting>

                <para>
                    The stub includes a <methodname>isElementPresent()</methodname>
                    helper, which is used by some commands, but is not normally needed.
                </para>

            <programlisting><?pocket-size 65% ?><![CDATA[	private boolean isElementPresent(By by) {
		try {
			driver.findElement(by);
			return true;
		} catch (NoSuchElementException e) {
			return false;
		}
	}
}]]></programlisting>
            </simplesect>
        </section>

        <section xml:id="testbench.development.eclipse">
            <title>Running JUnit Tests in Eclipse</title>

            <para>
                The Eclipse IDE integrates JUnit with nice control features
            </para>

            <orderedlist>
                <listitem>
                    Add the TestBench JAR to a library folder in the project, such as
                    <filename>lib</filename>. You should not put the library in
                    <filename>WEB-INF/lib</filename> as it is not used by the Vaadin web
                    application. Refresh the project by selecting it and pressing
                    <keycap>F5</keycap>.
                </listitem>
                <listitem>
                    Right-click the project in Project Explorer and select
                    <guilabel>Properties</guilabel>, and open the <guilabel>Java Build
                    Path</guilabel> and the <guilabel>Libraries</guilabel> tab. Click
                    <guibutton>Add JARs</guibutton>, navigate to the library folder,
                    select the library, and click <guibutton>OK</guibutton>.
                </listitem>
                <listitem>
                    Switch to the <guilabel>Order and Export</guilabel> tab in the project
                    properties. Make sure that the TestBench JAR is above the
                    <filename>gwt-dev.jar</filename> (it may contain an old
                    <filename>httpclient</filename> package), by selecting it and moving
                    it with the <guibutton>Up</guibutton> and <guibutton>Down</guibutton>
                    buttons.
                </listitem>
                <listitem>
                    Click <guibutton>OK</guibutton> to exit the project properties.
                </listitem>
                <listitem>
                    Right-click a test source file and select <menuchoice><guimenu>Run
                    As</guimenu><guimenuitem>JUnit Test</guimenuitem></menuchoice>.
                </listitem>
            </orderedlist>

            <para>
                A JUnit view should appear, and it should open the Firefox browser, launch
                the application, run the test, and then close the browser window. If all
                goes well, you have a passed test case, which is reported in the JUnit
                view area in Eclipse, as illustrated in <xref
                linkend="figure.testbench.development.eclipse"/>.
            </para>

            <figure xml:id="figure.testbench.development.eclipse">
                <title>Running JUnit Tests in Eclipse</title>
                <mediaobject>
                    <imageobject>
                        <imagedata scale="85" smallscale="100%" align="center" fileref="img/testbench/screenshots/eclipse-junit-run.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                If you are using some other IDE, it might support JUnit tests as well. If
                not, you can run the tests using Ant or Maven.
            </para>
        </section>

        <section xml:id="testbench.development.setup">
            <title>Test Setup</title>

            <para>
                Test configuration is done in a method annotated with
                <literal>@Before</literal>. The method is executed before each test
                case. In a JUnit stub exported from Recorder, this is done in the
                <methodname>setUp()</methodname> method.
            </para>

            <para>
                The basic configuration tasks are:
            </para>

            <itemizedlist>
                <listitem>Set TestBench parameters</listitem>
                <listitem>Create the web driver</listitem>
                <listitem>Do any other initialization</listitem>
            </itemizedlist>

            <section xml:id="testbench.development.setup.parameters">
                <title>TestBench Parameters</title>

                <para>
                    TestBench parameters are defined with static methods in the
                    <classname>com.vaadin.testbench.Parameters</classname> class. The
                    parameters are mainly for screenshots and documented in <xref
                    linkend="testbench.screenshots"/>.
                </para>
            </section>
        </section>

        <section xml:id="testbench.development.setup.webdriver">
            <title>Creating and Closing a Web Driver</title>
            
            <para>
                Vaadin TestBench uses Selenium WebDriver to execute tests in a
                browser. The <classname>WebDriver</classname> instance is created with the
                static <methodname>createDriver()</methodname> method in the
                <classname>TestBench</classname> class. It takes the driver as the
                parameter and returns it after registering it. The test cases must extend
                the <classname>TestBenchTestCase</classname> class, which manages the
                TestBench-specific features.
            </para>

            <para>
                The basic way is to create the driver in a method annotated with the
                JUnit <literal>@Before</literal> annotation and close it in a method
                annotated with <literal>@After</literal>.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    private WebDriver driver;

    @Before
    public void setUp() throws Exception {
        ...
        driver = TestBench.createDriver(new FirefoxDriver());
    }
    ...
    @After
    public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>

            <para>
                This creates the driver for each test you have in the test class, causing
                a new browser instance to be opened and closed. If you want to keep the
                browser open between the test, you can use <literal>@BeforeClass</literal>
                and <literal>@AfterClass</literal> methods to create and quit the
                driver. In that case, the methods as well as the driver instance have to
                be static.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    static private WebDriver driver;

    @BeforeClass
    static public void createDriver() throws Exception {
        driver = TestBench.createDriver(new FirefoxDriver());
    }
    ...
    @AfterClass
    static public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>
        </section>

        <section xml:id="testbench.development.basic">
            <title>Basic Test Case Structure</title>

            <para>
                A typical test case does the following:
            </para>

            <orderedlist>
                <listitem>Open the URL</listitem>
                <listitem>Navigate to desired state
                    <orderedlist>
                        <listitem>Find a HTML element (<classname>WebElement</classname>) for navigation</listitem>
                        <listitem>Use <methodname>click()</methodname> and other commands to interact with the element</listitem>
                        <listitem>Repeat with different elements until desired state is reached</listitem>
                    </orderedlist>
                </listitem>
                <listitem>Find a HTML element (<classname>WebElement</classname>) to check</listitem>
                <listitem>Get and assert the value of the HTML element</listitem>
                <listitem>Get a screenshot</listitem>
            </orderedlist>

            <para>
                The <classname>WebDriver</classname> allows finding HTML elements in a
                page in various ways, for example, with XPath expressions. The access
                methods are defined statically in the <classname>By</classname> class.
            </para>

            <para>
                These tasks are realized in the following test code:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testCase1() throws Exception {
    driver.get(baseUrl + "/book-examples/tobetested");
    
    // Get the button's element.
    // (Actually the caption element inside the button.)
    // Use the debug ID given with setDebugId().
    WebElement button = driver.findElement(By.xpath(
        "//div[@id='main.button']/span/span"));
    
    // Get the caption text
    assertEquals("Push Me!", button.getText());
    
    // And click it. It's OK to click the caption element.
    button.click();
    
    // Get the Label's element.
    // Use the automatically generated ID.
    WebElement label = driver.findElement(By.xpath(
        "//div[@id='myapp-949693921']" +
        "/div/div[2]/div/div[2]/div/div"));

    // Make the assertion
    assertEquals("Thanks!", label.getText());
}]]></programlisting>

            <para>
                You can also use URI fragments in the URL to open the application at a
                specific state. For information about URI fragments, see <xref
                linkend="advanced.urifu"/>.
            </para>

            <para>
                You should use the JUnit assertion commands. They are static methods
                defined in the <package>org.junit.Assert</package> class, which you can
                import (for example) with:
            </para>

            <programlisting><![CDATA[import static org.junit.Assert.assertEquals;]]></programlisting>

            <para>
                Please see the Selenium API documentation for a complete reference of the
                element search methods in the <classname>WebDriver</classname> and
                <classname>By</classname> classes and for the interaction commands in the
                <classname>WebElement</classname> class.
            </para>

            <para>
                TestBench has a collection of its own commands, defined in the
                <classname>TestBenchCommands</classname> object, which you can get by
                calling <literal>testBench(driver)</literal> in a test case.
            </para>
        </section>

        <section xml:id="testbench.development.tooltip">
            <title>Testing Tooltips</title>

            <para>
                Component tooltips show when you hover the mouse over a component. Events
                caused by hovering are not recorder by Recorder, so this interaction
                requires special handling when testing.
            </para>

            <para>
                Let us assume that you have set the tooltip as follows:
            </para>

            <programlisting><![CDATA[// Create a button with a debug ID
Button button = new Button("Push Me!");
button.setDebugId("main.button");

// Set the tooltip        
button.setDescription("This is a tip");]]></programlisting>

            <para>
                The tooltip of a component is displayed with the
                <methodname>showTooltip()</methodname> method in the
                <classname>TestBenchElementCommands</classname> object. You should wait a
                little to make sure it comes up. The floating tooltip element is not under
                the element of the component, but you can find it by the CSS selector
                <literal>div.v-tooltip</literal>.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testTooltip() throws Exception {
    driver.get(appUrl);
    
    // Get the button's element.
    // Use the debug ID given with setDebugId().
    WebElement button = driver.findElement(By.xpath(
        "//div[@id='main.button']/span/span"));
    
    // Show the tooltip
    tbElement(button).showTooltip();
    
    // Wait a little to make sure it's up
    Thread.sleep(1000);
    
    // Check that the tooltip text matches
    assertEquals("This is a tip", driver.findElement(
        By.cssSelector("div.v-tooltip")).getText());
    
    // Compare a screenshot just to be sure
    assertTrue(testBench(driver).compareScreen("tooltip"));
}]]></programlisting>

        </section>

        <section xml:id="testbench.development.contextmenu">
            <title>Testing Context Menus</title>

            <para>
                TBD
            </para>
        </section>
    </section>

    <section xml:id="testbench.screenshots">
        <title>Taking and Comparing Screenshots</title>

        <para>
            A screenshot can be taken automatically when a test fails, or manually for
            comparison with a reference screenshot taken earlier.
        </para>
        
        <para>
            Screenshots cover the page area in the browser. The browser is automatically
            maximized to fullscreen. The screenshot size therefore depends on the screen
            size, which is relevant for screenshot comparison.
        </para>

        <section xml:id="testbench.screenshots.parameters">
            <title>Screenshot Parameters</title>

            <para>
                The screenshot configuration parameters are defined with static methods in
                the <classname>com.vaadin.testbench.Parameters</classname> class.
            </para>

            <variablelist>
                <varlistentry>
                    <term><parameter>screenshotErrorDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where screenshots for failed tests or
                        comparisons are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotReferenceDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where the reference images for screenshot
                        comparison are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>captureScreenshotOnFailure</parameter> (default: <literal>true</literal>)</term>
                    <listitem>
                        Defines whether screenshots are taken whenever an assertion fails.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonTolerance</parameter> (default: <literal>0.25</literal>)</term>
                    <listitem>
                        Screen comparison is usually not done with exact pixel values,
                        because rendering in browser often has some tiny
                        inconsistencies. Also image compression may cause small artifacts.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonCursorDetection</parameter> (default: <literal>false</literal>)</term>
                    <listitem>
                        Some field component get a blinking cursor when they have the
                        focus. The cursor can cause unnecessary failures depending on
                        whether the blink happens to make the cursor visible or invisible
                        when taking a screenshot. This parameter enables cursor detection
                        that tries to minimize these failures.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>maxScreenshotRetries</parameter> (default: 2)</term>
                    <listitem>
                        Sometimes a screenshot comparison may fail because the screen
                        rendering has not yet finished, or there is a blinking cursor that
                        is different from the reference screenshot. For these reasons,
                        Vaadin TestBench retries the screenshot comparison for a number of
                        times defined with this parameter.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotRetryDelay</parameter> (default: <literal>500</literal>)</term>
                    <listitem>
                        Delay in milliseconds for making a screenshot retry when a
                        comparison fails.
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                For example:
            </para>

        </section>

        <section xml:id="testbench.screenshots.failure">
            <title>Taking Screenshots on Failure</title>

            <para>
                Vaadin TestBench takes screenshots automatically when a test fails, if the
                <parameter>captureScreenShotOnFailure</parameter> is enabled in TestBench
                parameters. The screenshots are written to the error directory defined
                with the <parameter>screenshotErrorDirectory</parameter> parameter.
            </para>

            <para>
                You need to have the following in the setup method:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    Parameters.setScreenshotErrorDirectory("screenshots/errors");
    Parameters.setCaptureScreenshotOnFailure(true);
    ...
}]]></programlisting>

        </section>

        <section xml:id="testbench.screenshot.comparison">
            <title>Taking Screenshots for Comparison</title>

            <para>
                Vaadin TestBench allows taking screenshots of the web browser window with
                the <methodname>compareScreen()</methodname> command in the
                <classname>TestBenchCommands</classname> object. Most commonly, you use
                the variant of the method that accepts a screenshot identifier string. The
                actual filename includes also browser information.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[assertTrue(testBench(driver).compareScreen("tooltip"));]]></programlisting>

            <para>
                Screenshots taken this way are compared to a reference image stored in the
                reference image folder. If differences are found (or the reference image
                is missing), the comparison method returns <literal>false</literal> and
                stores the screenshot in the error folder.
            </para>

            <section xml:id="testbench.screenshot.comparison.error-images">
                <title>Screenshot Comparison Error Images</title>

                <para>
                    Screenshots with errors are written to the error folder, which is
                    defined with the <parameter>screenshotErrorDirectory</parameter>
                    parameter described in <xref
                    linkend="testbench.screenshots.parameters"/>.
                </para>

                <para>
                    For example, the error caused by a missing reference image could be
                    written to
                    <filename>screenshot/errors/tooltip_firefox_12.0.png</filename>. The
                    image is shown in <xref
                    linkend="figure.testbench.screenshot.comparison.error-images.calc"/>.
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.error-images.calc">
                    <title>A screenshot taken by a test run</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="60" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>

                <para>
                    When taking screenshots, the browser is maximized to full screen. Only the page
                    view area in the browser is captured.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.reference-images">
                <title>Reference Images</title>

                <para>
                    Reference images are expected to be found in the reference image
                    folder, as defined with the
                    <parameter>screenshotErrorDirectory</parameter> parameter described in
                    <xref linkend="testbench.screenshots.parameters"/>.  To create a
                    reference image, just copy a screenshot from the
                    <filename>errors/</filename> directory to the
                    <filename>reference/</filename> directory.
                </para>

                <para>
                    For example:
                </para>

                <screen><prompt>$</prompt> <command>cp</command> <parameter>screenshot/errors/tooltip_firefox_12.0.png</parameter> <parameter>screenshot/reference/</parameter></screen>

                <para>
                    Now, when the proper reference image exists, rerunning the test
                    outputs success:
                </para>

                <screen><prompt>$</prompt> <command>java</command> ...
JUnit version 4.5
.
Time: 18.222

OK (1 test)</screen>

                <para>
                    You can also supply multiple versions of the reference images by
                    appending an underscore and an index to the filenames. For example:
                </para>

                <screen>tooltip_firefox_12.0.png
tooltip_firefox_12.0_1.png
tooltip_firefox_12.0_2.png</screen>

                <para>
                    This can be useful in certain situations when there actually are more
                    than one "correct" reference.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.visualization">
                <title>Visualization of Differences in Screenshots with Highlighting</title>

                <para>
                    Vaadin TestBench supports advanced difference visualization between a
                    captured screenshot and the reference image. A difference report is
                    written to a HTML file that has the same name as the failed
                    screenshot, but with <filename>.html</filename> suffix. The reports are
                    written to the same <filename>errors/</filename> folder as the
                    screenshots from the failed tests.
                </para>

                <para>
                    The differences in the images are highlighted with blue
                    squares. Moving the mouse pointer over a square shows the difference
                    area as it appears in the reference image. Clicking the image switches
                    the entire view to the reference image and back. Text "<guilabel>Image
                    for this run</guilabel>" is displayed in the top-left corner to
                    identify the currently displayed screenshot.
                </para>

                <para>
                    <xref
                    linkend="figure.testbench.screenshot.comparison.visualization.highlighting"/>
                    shows a difference report with three differences. Date fields are a
                    typical cause of differences in screenshots.
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.visualization.highlighting">
                    <title>A highlighed error image and the reference image</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="120" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                    </mediaobject>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="120" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>
            </section>
        </section>

        <section xml:id="testbench.screenshot.comparison.practices">
            <title>Practices for Handling Screenshots</title>

            <para>
                Access to the screenshot reference image directory should be arranged
                so that a developer who can view the results can copy the valid images
                to the reference directory. One possibility is to store the reference
                images in a version control system and check-out them to the
                <filename>reference/</filename> directory.
            </para>

            <para>
                A build system or a continuous integration system can be configured to
                automatically collect and store the screenshots as build artifacts.
            </para>
        </section>
    </section>

    <section xml:id="testbench.grid">
        <title>Running Tests in a Grid</title>

        <para>
            A distributed test environment consists of a grid hub and a number of test
            nodes. The hub listens to calls from test runners and delegates them to the
            grid nodes. Different nodes can run on different operating system platforms
            and have different browsers installed.
        </para>

        <section xml:id="testbench.grid.remote">
            <title>Running Tests Remotely</title>

            <para>
                Remote tests are just like locally executed JUnit tests, except instead of
                using a browser driver, you use a <classname>RemoteWebDriver</classname>
                that can connects to the hub. The hub delegates the connection to a grid
                node with the desired capabilities, that is, which browsers are installed
                in a suitable node. The capabilities are described with a
                <classname>DesiredCapabilities</classname> object.
            </para>

            <para>
                For example, in the example tests given in the <filename>example</filename>
                folder, we create and use a remote driver as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testRemoteWebDriver() throws MalformedURLException {
    // Require Firefox in the test node
    DesiredCapabilities capability =
        DesiredCapabilities.firefox();

    // Create a remote web driver that connects to a hub
    // running in the local host
    WebDriver driver = TestBench.createDriver(
        new RemoteWebDriver(new URL(
            "http://localhost:4444/wd/hub"), capability));

    // Then use it to run a test as you would use any web driver
    try {
        driver.navigate().to(
            "http://demo.vaadin.com/sampler#TreeActions");
        WebElement e = driver.findElement(By.xpath(
            "//div[@class='v-tree-node-caption']"+
            "/div[span='Desktops']"));
        new Actions(driver).moveToElement(e).contextClick(e)
            .perform();
    } finally {
        driver.quit();
    }
}
]]></programlisting>

            <para>
                Running the example requires that the hub server and the nodes are
                running. These are purely Selenium functionalities, so please refer to the
                Selenium documentation for a distributed testing setup.
            </para>
        </section>

        <section>
            <title>Starting the Hub</title>
            
            <para>
                The TestBench grid hub listens to calls from test runners and
                delegates them to the grid nodes. The grid hub is included in the
                Vaadin TestBench JAR and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar \
       vaadin-testbench-standalone-3.0.0.jar \
       -role hub</screen>

            <para>
                You can open the control interface of the hub also with a web
                browser. Using the default port, just open URL
                <uri>http://localhost:4444/</uri>. Once you have started one or more grid
                nodes, as instructed in the next section, the "console" page displays a
                list of the grid nodes with their browser capabilities.
            </para>
        </section>

        <section>
            <title>Starting a Grid Node</title>

            <para>
                A TestBench grid node listens to calls from the hub and is capable of
                opening a browser. The grid hub is included in the Vaadin TestBench JAR
                and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar \
       vaadin-testbench-standalone-3.0.0.jar \
       -role node \
       -hub <parameter>http://localhost:4444/grid/register</parameter></screen>

            <para>
                The node registers itself in the grid hub and you need to give the address
                of the hub with the <parameter>-hub</parameter> parameter. You can run one
                grid node in the same host as the hub, as is done in the example above
                with the localhost address.
            </para>
        </section>

    </section>
</chapter>

<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:nil
sgml-shorttag:nil
sgml-namecase-general:nil
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:4
sgml-indent-data:t
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:("/etc/sgml/catalog" "/usr/share/xemacs21/xemacs-packages/etc/psgml-dtds/CATALOG")
sgml-local-ecat-files:("ECAT" "~/sgml/ECAT" "/usr/share/sgml/ECAT" "/usr/local/share/sgml/ECAT" "/usr/local/lib/sgml/ECAT")
End:
-->
